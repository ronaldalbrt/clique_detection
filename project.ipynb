{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geração dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch import\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "from ogb.nodeproppred import Evaluator\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.utils import erdos_renyi_graph\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(7)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a random graph with n nodes and p probability of edge creation and a clique of size clique_size\n",
    "def generate_graph(n, p, clique_size):\n",
    "    edge_index = erdos_renyi_graph(n, edge_prob=p)\n",
    "    clique_nodes = random.sample(range(n), clique_size)\n",
    "\n",
    "    x = torch.ones(n, 64).type(torch.float32)\n",
    "    class_label = torch.zeros(n).type(torch.int64)\n",
    "    class_label[clique_nodes] = 1\n",
    "\n",
    "    for i, node_i in enumerate(clique_nodes):\n",
    "        for node_j in clique_nodes[i + 1:]:\n",
    "            edge_to_add = torch.tensor([[node_i, node_j], [node_j, node_i]])\n",
    "            edge_index = torch.cat((edge_index, edge_to_add), 1)\n",
    "    \n",
    "    return Data(x=x, adj_t=torch.transpose(edge_index, 0, 1), y=class_label)\n",
    "\n",
    "train_data = [generate_graph(200, 0.5, 50) for _ in range(5000)]\n",
    "valid_data = [generate_graph(200, 0.5, 50) for _ in range(1000)]\n",
    "test_data = [generate_graph(200, 0.5, 50) for _ in range(1000)]\n",
    "\n",
    "class_weights = torch.tensor([50.0, 150.0])\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, num_workers=0)\n",
    "valid_loader = DataLoader(valid_data, batch_size=32, num_workers=0)\n",
    "test_loader = DataLoader(test_data, batch_size=32, num_workers=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GCN - Graph Convolutional Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "GCN_args = {\n",
    "    'device': device,\n",
    "    'num_layers': 3,\n",
    "    'hidden_dim': 256,\n",
    "    'dropout': 0.5,\n",
    "    'lr': 0.01,\n",
    "    'epochs': 20,\n",
    "}\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers,\n",
    "                 dropout, return_embeds=False):\n",
    "        super(GCN, self).__init__()\n",
    "\n",
    "        self.convs = None\n",
    "        self.bns = None\n",
    "        self.softmax = None\n",
    "\n",
    "        def get_in_channels(idx):\n",
    "            return hidden_dim if idx > 0 else input_dim\n",
    "\n",
    "        def get_out_channels(idx):\n",
    "            return hidden_dim if idx < num_layers - 1 else output_dim\n",
    "\n",
    "        self.convs = torch.nn.ModuleList([\n",
    "            GCNConv(in_channels=get_in_channels(i), out_channels=get_out_channels(i))\n",
    "            for i in range(num_layers)\n",
    "        ])\n",
    "\n",
    "        self.bns = torch.nn.ModuleList([\n",
    "            torch.nn.BatchNorm1d(num_features=get_out_channels(i))\n",
    "            for i in range(num_layers - 1)\n",
    "        ])\n",
    "\n",
    "        self.softmax = torch.nn.LogSoftmax(dim=1)\n",
    "        self.dropout = dropout\n",
    "        self.return_embeds = return_embeds\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "        for bn in self.bns:\n",
    "            bn.reset_parameters()\n",
    "\n",
    "    def forward(self, batched_data):\n",
    "        x, adj_t = batched_data.x, torch.transpose(batched_data.adj_t,0,1)\n",
    "\n",
    "        out = None\n",
    "\n",
    "        for gcn, bn in zip(self.convs[:-1], self.bns):\n",
    "            x = gcn(x, adj_t)\n",
    "            x = bn(x)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "\n",
    "        out = self.convs[-1](x, adj_t)\n",
    "        if not self.return_embeds:\n",
    "            out = self.softmax(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data_loader, optimizer, loss_fn):\n",
    "    model.train()\n",
    "    loss = 0\n",
    "\n",
    "    for batch in data_loader:\n",
    "        batch = batch.to(device)\n",
    "\n",
    "        if batch.x.shape[0] == 1 or batch.batch[-1] == 0:\n",
    "            pass\n",
    "        else:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            preds = model(batch)\n",
    "            labels = batch.y.to(device)\n",
    "            loss = loss_fn(preds, labels.squeeze())\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "# The evaluation function\n",
    "def eval(model, loader, evaluator):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    for batch in loader:\n",
    "        batch = batch.to(device)\n",
    "\n",
    "        if batch.x.shape[0] == 1:\n",
    "            pass\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                pred = model(batch).argmax(dim=-1, keepdim=True)\n",
    "\n",
    "            y_true.append(batch.y.view(pred.shape).detach().cpu())\n",
    "            y_pred.append(pred.detach().cpu())\n",
    "\n",
    "    y_true = torch.cat(y_true, dim = 0).numpy()\n",
    "    y_pred = torch.cat(y_pred, dim = 0).numpy()\n",
    "\n",
    "    input_dict = {\"y_true\": y_true, \"y_pred\": y_pred}\n",
    "\n",
    "    return evaluator.eval(input_dict)[\"acc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 64\n",
    "num_labels = 2\n",
    "\n",
    "model = GCN(num_features, GCN_args['hidden_dim'],\n",
    "            num_labels, GCN_args['num_layers'],\n",
    "            GCN_args['dropout']).to(device)\n",
    "\n",
    "evaluator = Evaluator(name='ogbn-arxiv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 01, Loss: 0.6958, Train: 25.00%, Valid: 25.00% Test: 25.00%\n",
      "Training...\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "model.reset_parameters()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=GCN_args['lr'])\n",
    "loss_fn = CrossEntropyLoss(class_weights.to(device))\n",
    "\n",
    "best_model = None\n",
    "best_valid_acc = 0\n",
    "\n",
    "for epoch in range(1, 1 + GCN_args[\"epochs\"]):\n",
    "  print('Training...')\n",
    "  loss = train(model, train_loader, optimizer, loss_fn)\n",
    "\n",
    "  print('Evaluating...')\n",
    "  train_result = eval(model, train_loader, evaluator)\n",
    "  val_result = eval(model, valid_loader, evaluator)\n",
    "  test_result = eval(model, test_loader, evaluator)\n",
    "\n",
    "  train_acc, valid_acc, test_acc = train_result, val_result, test_result\n",
    "  if valid_acc > best_valid_acc:\n",
    "      best_valid_acc = valid_acc\n",
    "      best_model = copy.deepcopy(model)\n",
    "      \n",
    "  print(f'Epoch: {epoch:02d}, '\n",
    "        f'Loss: {loss:.4f}, '\n",
    "        f'Train: {100 * train_acc:.2f}%, '\n",
    "        f'Valid: {100 * valid_acc:.2f}% '\n",
    "        f'Test: {100 * test_acc:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_graph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
