{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch import\n",
    "from dataset import generate_graph, generate_dataset\n",
    "from config import *\n",
    "\n",
    "G = generate_graph(200, 0.5, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GIN(\n",
       "  (convs): ModuleList(\n",
       "    (0): GINConv(nn=Sequential(\n",
       "      (0): Linear(in_features=1, out_features=64, bias=True)\n",
       "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (4): ReLU()\n",
       "    ))\n",
       "    (1-3): 3 x GINConv(nn=Sequential(\n",
       "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (4): ReLU()\n",
       "    ))\n",
       "    (4): GINConv(nn=Sequential(\n",
       "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): Linear(in_features=64, out_features=2, bias=True)\n",
       "      (4): ReLU()\n",
       "    ))\n",
       "  )\n",
       "  (bns): ModuleList(\n",
       "    (0-3): 4 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (softmax): LogSoftmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn import Sequential, Linear, ReLU, BatchNorm1d\n",
    "from models.GCN_model import GCN\n",
    "from models.GraphSAGE_model import GraphSAGE\n",
    "from models.GAT_model import GAT\n",
    "from models.GIN_model import GIN\n",
    "\n",
    "\n",
    "GIN_args = {\n",
    "    'device': device,\n",
    "    'num_layers': 5,\n",
    "    'hidden_dim': 64,\n",
    "    'dropout': 0.5,\n",
    "    'lr': 0.1,\n",
    "    'epochs': 100,\n",
    "    'mlp_hidden_dim': 64,\n",
    "    'mlp': lambda input_dim, hidden_dim, output_dim: Sequential(Linear(input_dim, hidden_dim), BatchNorm1d(hidden_dim), ReLU(), Linear(hidden_dim, output_dim), ReLU())\n",
    "}\n",
    "\n",
    "num_features = 1\n",
    "num_labels = 2\n",
    "\n",
    "model = GIN(num_features, \n",
    "            GIN_args['mlp'], GIN_args['mlp_hidden_dim'],\n",
    "            GIN_args['hidden_dim'],\n",
    "            num_labels, GIN_args['num_layers'],\n",
    "            GIN_args['dropout']).to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(trained_models_dir+\"/GIN_model.pt\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_results': {'roc_auc': 0.6966666666666667,\n",
       "  'acc': 0.3175,\n",
       "  'f1': 0.42283298097251587,\n",
       "  'precision': 0.2680965147453083,\n",
       "  'recall': 1.0},\n",
       " 'valid_results': {'roc_auc': 0.875,\n",
       "  'acc': 0.625,\n",
       "  'f1': 0.5714285714285715,\n",
       "  'precision': 0.4,\n",
       "  'recall': 1.0},\n",
       " 'test_results': {'roc_auc': 0.6174999999999999,\n",
       "  'acc': 0.25,\n",
       "  'f1': 0.4,\n",
       "  'precision': 0.25,\n",
       "  'recall': 1.0}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle \n",
    "\n",
    "with open(results_dir+\"GIN_results.pickle\", \"rb\") as f:\n",
    "    results = pickle.load(f)\n",
    "\n",
    "results['best']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(G.to(device)).argmax(dim=-1, keepdim=True).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0,\n",
       "        0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0,\n",
       "        0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0,\n",
       "        1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 0, 0, 1, 0, 0, 0], device='cuda:0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_graph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
